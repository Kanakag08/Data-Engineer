{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff949122-c73d-4e1f-ab67-acbc2432b369",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (47433212.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install findspark\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install findspark\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Pratice\").getOrCreate\n",
    "spark\n",
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0a3187-e211-41f8-8874-d7008732c78c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'sparkContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m spark\n\u001b[0;32m      5\u001b[0m dataList \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20000\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100000\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScala\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3000\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m rdd\u001b[38;5;241m=\u001b[39m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkContext\u001b[49m\u001b[38;5;241m.\u001b[39mparallelize(dataList)\n\u001b[0;32m      7\u001b[0m rdd\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'sparkContext'"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Pratice\").getOrCreate\n",
    "spark\n",
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a598a6b-71d3-47c4-a7ec-190e5fa5120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de604380-0958-4619-9da3-4681931578d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9086e03-99bc-4795-bdb5-af38f6c1f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Pratice\").getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ef72a42-b763-49e9-9f41-7c15cf8db570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.Builder.getOrCreate of <pyspark.sql.session.SparkSession.Builder object at 0x000002587573F980>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e24147-9a05-4dd7-98c7-76b0884225a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\kanak agrawal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\kanak agrawal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326479c8-a2aa-471b-9f14-e91c51e8a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findsparkNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c3975a-8477-4462-bad1-494e24bff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e8d32b-93a8-48bc-a3fc-d6952d22ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d2db96-8344-4e33-aae1-2e1b377a2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b902812-a847-4a44-a3dc-12c0558b6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Pratice\").getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c40779-9245-4375-bcf1-77a22ea9faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.Builder.getOrCreate of <pyspark.sql.session.SparkSession.Builder object at 0x00000224E62DC680>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3cd1711-4904-408f-9a7e-d7a69da040f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Java', 20000), ('Python', 100000), ('Scala', 3000)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Test').getOrCreate()\n",
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "rdd.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a057e5-5826-4195-bc61-29fe49a8a9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
